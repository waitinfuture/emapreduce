# 创建集群

本文介绍创建E-MapReduce（简称EMR）集群的详细操作步骤和相关配置。

已完成RAM授权，操作步骤请参见[角色授权](/cn.zh-CN/集群管理/集群规划/角色授权.md)。

## 操作步骤

1.  进入创建集群页面。

    1.  登录[阿里云E-MapReduce控制台](https://emr.console.aliyun.com/)。

    2.  在顶部菜单栏处，根据实际情况选择地域和资源组。

        -   地域：创建的集群将会在对应的地域内，一旦创建不能修改。
        -   资源组：默认显示账号全部资源。
    3.  单击**创建集群**，进行创建。

2.  配置集群信息。

    创建集群时，您需要对集群进行软件配置、硬件配置和基础配置。

    **说明：** 集群创建完成后，除了集群名称以外，其他配置均无法修改，所以在创建时请仔细确认各项配置。

    1.  软件配置。

        |配置项|说明|
        |---|--|
        |**集群类型**|当前支持的集群类型如下：         -   **Hadoop**：
            -   提供半托管的Hadoop、Hive和Spark离线大规模分布式数据存储和计算。
            -   提供SparkStreaming、Flink和Storm流式数据计算。
            -   提供Presto和Impala交互式查询。
            -   提供Oozie和Pig等Hadoop生态圈的组件。
        -   **Kafka**：是半托管分布式的、高吞吐量和高可扩展性的消息系统。提供一套完整的服务监控体系和元数据管理。广泛用于日志收集、监控数据聚合等场景，支持离线或流式数据处理、实时数据分析等。
        -   **Zookeeper**：提供独立的分布式一致性锁服务，适用于大规模的Hadoop集群、HBase集群和Kafka集群。
        -   **Druid**：提供半托管式实时交互式分析服务，大数据查询毫秒级延迟，支持多种数据摄入方式，可以与EMR Hadoop、EMR Spark、OSS和RDS等服务搭配组合使用，构建灵活稳健的实时查询解决方案。
        -   **Data Science**：主要面向大数据+AI场景，提供Hive和Spark离线大数据ETL和TensorFlow模型训练，您可以选择CPU+GPU的异构计算框架，通过英伟达GPU对部分深度学习算法进行高性能计算。
        -   **Dataflow**：提供的基于Apache Flink官方产品Ververica和E-MapReduce Hadoop构建的企业级大数据计算平台，完全兼容开源Flink API，并提供额外商业增值能力。 |
        |**云原生选项**|默认**on ECS**。|
        |**产品版本**|默认最新的软件版本。|
        |**必选服务**|默认的服务组件，后期可以在管理页面中启停服务。|
        |**可选服务**|根据您的实际需求选择其他的一些组件，被选中的组件会默认启动相关的服务进程。 **说明：** 组件越多，对机器的配置要求也越高，所以在下面的步骤中您需要根据实际的组件数量进行机器选型，否则可能没有足够的资源运行这些服务。 |
        |**高级设置**|        -   **Kerberos集群模式**：是否开启集群的Kerberos认证功能。默认不开启。通常个人用户集群无需该功能。
        -   **软件自定义配置**：可指定JSON文件对集群中的基础软件（例如Hadoop、Spark和Hive等）进行配置，详细使用方法请参见[软件配置](/cn.zh-CN/集群管理/第三方软件/软件配置.md)。默认不开启。 |

    2.  硬件配置。

        |区域|配置项|说明|
        |--|---|--|
        |**付费类型**|**付费类型**|默认包年包月。当前支持的付费类型如下：         -   **按量付费**：一种后付费模式，即先使用再付费。按量付费是根据实际使用的小时数来支付费用，每小时计费一次，适合短期的测试任务或是灵活的动态任务。
        -   **包年包月**：一种预付费模式，即先付费再使用。

**说明：**

建议测试场景下使用**按量付费**，测试正常后再新建一个**包年包月**的生产集群正式使用。 |
        |**网络配置**|**可用区**|可用区为在同一地域下的不同物理区域，可用区之间内网互通。一般使用默认的可用区即可。|
        |**网络类型**|默认专有网络。|
        |**VPC**|选择在该地域的VPC。如没有，单击**创建 VPC / 子网（交换机）**前往新建。|
        |**交换机**|选择在对应VPC下可用区的交换机，如果在这个可用区没有可用的交换机，则需要新创建一个。|
        |**安全组名称**|您可直接输入安全组名称来新建一个安全组。如果已有在使用的安全组，则可直接选择使用。 **说明：** 安全组名称长度限制为2~64个字符，必须以大小写字母或中文开头，可以使用中文、字母、数字、中划线（-）和下划线（\_）。 |
        |**高可用**|**高可用**|默认不开启。打开**高可用**开关，Hadoop集群会有两个或三个Master节点来支持ResourceManager和NameNode的高可用。 HBase集群原本就支持高可用，只是另一个节点用其中一个Core节点来充当，如果打开高可用，会独立使用一个Master节点来支持高可用，更加的安全可靠。 |
        |**实例**|**选型配置**|        -   **Master 实例**：主要负责ResourceManager和NameNode等控制进程的部署。

您可以根据需要选择实例规格，详情请参见[实例规格族](/cn.zh-CN/实例/实例规格族.md)。

            -   **系统盘配置**：根据需要选择SSD云盘、ESSD云盘或者高效云盘。
            -   **系统盘大小**：根据需要调整磁盘容量，推荐至少120 GB。取值范围为40 ~ 2048 GB。
            -   **数据盘配置**：根据需要选择SSD云盘、ESSD云盘或者高效云盘。
            -   **数据盘大小**：根据需要调整磁盘容量，推荐至少80 GB。取值范围为40 ~ 32768 GB。
            -   **Master数量**：默认1台。如果开启高可用默认2或者3台。
        -   **Core 实例**：主要负责集群所有数据的存储，创建集群完成后也支持按需进行扩容。
            -   **系统盘配置**：根据需要选择SSD云盘、ESSD云盘或者高效云盘。
            -   **系统盘大小**：根据需要调整磁盘容量，推荐至少120 GB。
            -   **数据盘配置**：根据需要选择SSD云盘、ESSD云盘或者高效云盘。
            -   **数据盘大小**：根据需要调整磁盘容量，推荐至少80 GB。
            -   **Core数量**：默认2台，根据需要调整。
        -   **Task 实例**：不保存数据，调整集群的计算力使用。默认不开启，需要时再追加。 |

    3.  基础配置。

        |区域|配置项|说明|
        |--|---|--|
        |**基础信息**|**集群名称**|集群的名字，长度限制为1~64个字符，仅可使用中文、字母、数字、中划线（-）和下划线（\_）。|
        |**元数据选择**|        -   **集群内置MySQL**：表示元数据存储在集群本地环境的MySQL数据库中。
        -   **统一meta数据库**：表示使用统一的集群外部的meta数据库，集群释放后meta信息依然存在，更多信息请参见[管理Hive统一元数据](/cn.zh-CN/元数据管理/Hive元数据/管理Hive统一元数据.md)。
        -   **独立RDS MySQL**：表示使用自建的阿里云RDS作为元数据库，更多信息请参见[配置独立RDS MySQL](/cn.zh-CN/元数据管理/Hive元数据/配置独立RDS.md)。
推荐选择**独立RDS MySQL**。|
        |**挂载公网**|集群是否挂载弹性公网IP地址，默认不开启。 **说明：** 当**元数据选择**选择**统一meta数据库**时，默认不开启**挂载公网**，该功能目前仅支持Kafka类型的集群。创建集群后只能通过内网访问E-MapReduce集群，创建后如果您需要使用公网IP地址访问，请在ECS上申请开通公网IP地址，详情请参见[弹性公网IP](/cn.zh-CN/网络/实例IP地址介绍/弹性公网IP.md)中的申请EIP的内容。 |
        |**远程登录**|是否打开安全组22端口，默认不开启。|
        |**密钥对**|关于密钥对的使用详情请参见[SSH密钥对](/cn.zh-CN/安全/SSH密钥对/SSH密钥对概述.md)。|
        |**登录密码**|设置Master节点的登录密码，密码规则：8~30个字符，且必须同时包含大写字母、小写字母、数字和特殊字符。 特殊字符包括：感叹号（!）、at（@）、井号（\#）、美元符号（$）、百分号（%）、乘方（^）、and（&）和星号（\*）。 |
        |**高级设置**|**添加用户**|添加访问开源大数据软件Web UI的账号。|
        |**权限设置**|通过RAM角色为在集群上运行的应用程序提供调用其他阿里云服务所需的必要权限，无需调整，使用默认即可。         -   **服务角色**：用户将权限授予EMR服务，允许EMR代表用户调用其他阿里云的服务，例如ECS和OSS。
        -   **ECS应用角色**：当用户的程序在EMR计算节点上运行时，可不填写阿里云AccessKey来访问相关的云服务（例如OSS），EMR会自动申请一个临时AccessKey来授权本次访问。**ECS应用角色**用于控制这个AccessKey的权限。 |
        |**引导操作**|可选配置，您可以在集群启动Hadoop前执行您自定义的脚本，详情请参见[引导操作](/cn.zh-CN/集群管理/第三方软件/引导操作.md)。|
        |**标签**|可选配置，您可以在创建集群时绑定标签，也可以在集群创建完成后，在集群详情页绑定标签，详情请参见[管理集群标签](/cn.zh-CN/集群管理/集群配置/管理集群标签.md)。|
        |**资源组**|可选配置。详情请参见[使用资源组](/cn.zh-CN/集群管理/集群配置/使用资源组.md)。|

        **说明：** 页面右边会显示您所创建集群的配置清单以及集群费用。根据不同的付费类型，展示不同的价格信息。

    4.  当所有的信息确认正确有效后，单击**创建**。

        **说明：**

        -   按量付费集群：立刻开始创建。

            集群创建完成后，集群的状态变为**空闲**。

        -   包年包月集群：先生成订单，在支付完成订单以后集群才会开始创建。
3.  登录Core节点。

    1.  在Master节点上切换到hadoop账号。

        ```
        su hadoop
        ```

    2.  免密码SSH登录到对应的Core节点。

        ```
        ssh emr-worker-1
        ```

    3.  通过`sudo`命令获得root权限。

        ```
        sudo su - root
        ```


## 问题反馈

如果您在使用阿里云E-MapReduce过程中有任何疑问，欢迎您扫描下面的二维码加入钉钉群进行反馈。

![emr_dingding](https://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/zh-CN/2440659951/p81620.png)

